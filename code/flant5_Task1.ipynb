{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flant5 task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "from huggingface_hub import HfFolder\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score, precision_score,recall_score,f1_score\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mnt/Data/rishav_2311mc12/anaconda3/envs/TextTime/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a747adc4212b4fbbaba189cf037aba0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5945 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1162f3fd1f4fe49e32f2de7a22ccaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /mnt/Data/rishav_2311mc12/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29725' max='29725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29725/29725 3:48:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.030300</td>\n",
       "      <td>0.827047</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.718954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.686063</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>0.461176</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.923200</td>\n",
       "      <td>0.944154</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.656471</td>\n",
       "      <td>0.721863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>0.931072</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.677647</td>\n",
       "      <td>0.728192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.751900</td>\n",
       "      <td>1.088727</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.752823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>1.178025</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.703529</td>\n",
       "      <td>0.754098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>1.243401</td>\n",
       "      <td>0.771765</td>\n",
       "      <td>0.795396</td>\n",
       "      <td>0.731765</td>\n",
       "      <td>0.762255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>1.302643</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.703529</td>\n",
       "      <td>0.745636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>1.605120</td>\n",
       "      <td>0.765882</td>\n",
       "      <td>0.767773</td>\n",
       "      <td>0.762353</td>\n",
       "      <td>0.765053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.901078</td>\n",
       "      <td>0.767059</td>\n",
       "      <td>0.768322</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.766509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>1.915429</td>\n",
       "      <td>0.775294</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.755294</td>\n",
       "      <td>0.770708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4950973f57fa45b687f359e1bd85006a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='850' max='850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [850/850 01:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8542985916137695, 'eval_Accuracy': 0.7752941176470588, 'eval_Precision': 0.7896039603960396, 'eval_Recall': 0.7505882352941177, 'eval_F1 Score': 0.7696019300361882, 'eval_runtime': 93.1322, 'eval_samples_per_second': 9.127, 'eval_steps_per_second': 9.127, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "label2id = {\"0\": 0, \"1\": 1}\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "\n",
    "def format_data_T2(row, flag=-1):\n",
    "    prompt = f\"Text: {row['old_cleaned_content']}\\nAnswer:\"\n",
    "    completion = \"Yes\" if row['Ground-Truth'] == 1 else \"No\"\n",
    "\n",
    "    base_prompt = \"\"\"Analyze the given text based on its contextual understanding to determine whether any factual updates (e.g., date changes, numerical updates, score modifications, or status changes) are likely to occur in the future. \n",
    "    Return a response indicating \"Yes\" if an update is predicted and \"No\" otherwise.\\n\"\"\"\n",
    "\n",
    "    formatted_entry = {\"prompt\": base_prompt + prompt, \"completion\": completion} if flag == 1 else {\"prompt\": base_prompt + prompt, \"completion\": ''}\n",
    "    return json.dumps(formatted_entry)\n",
    "\n",
    "def load_dataset(model_type: str = \"\") -> Dataset:\n",
    "    if model_type == \"AutoModelForSequenceClassification\":\n",
    "        train_df = pd.read_csv(\"/mnt/Data/rishav_2311mc12/Revision/data/train.csv\", encoding='ISO-8859-1')\n",
    "        test_df = pd.read_csv(\"/mnt/Data/rishav_2311mc12/Revision/data/val.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "        train_df[\"text\"] = train_df.apply(lambda row: format_data_T2(row, flag=0), axis=1)\n",
    "        test_df[\"text\"] = test_df.apply(lambda row: format_data_T2(row, flag=0), axis=1)\n",
    "\n",
    "\n",
    "        # Apply the function to each row and store the result in a new column 'text'\n",
    "        train_df.drop(columns=['old_cleaned_content','new_cleaned_content'], inplace=True)\n",
    "        test_df.drop(columns=['old_cleaned_content','new_cleaned_content'], inplace=True)\n",
    "\n",
    "        train_df.rename(columns={'Ground-Truth': 'labels'}, inplace=True)\n",
    "        test_df.rename(columns={'Ground-Truth': 'labels'}, inplace=True) \n",
    "\n",
    "        dataset_train = Dataset.from_pandas(train_df)\n",
    "        dataset_test = Dataset.from_pandas(test_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': dataset_train,\n",
    "            'test': dataset_test\n",
    "        })  \n",
    "\n",
    "    return dataset\n",
    "\n",
    "MODEL_ID = \"google/flan-t5-large\"\n",
    "REPOSITORY_ID = \"rishavranaut/flanT5_Task2\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_ID, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model.to(\"cuda\") if torch.cuda.is_available() else model.to(\"cpu\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=5,\n",
    "    output_dir = REPOSITORY_ID,\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    weight_decay = 0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=2500,\n",
    "    report_to=\"tensorboard\",\n",
    "    evaluation_strategy = 'steps',\n",
    "    save_strategy='steps',\n",
    "    save_steps=2500, \n",
    "    load_best_model_at_end = False,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id= REPOSITORY_ID,\n",
    "    hub_token='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',\n",
    "    resume_from_checkpoint=True\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize_function(examples) -> dict:\n",
    "    \"\"\"Tokenize the text column in the dataset\"\"\"\n",
    "    sentences = [\n",
    "        text for text in examples['text']\n",
    "    ]\n",
    "    return tokenizer(sentences, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "def compute_metrics(eval_pred) -> dict:\n",
    "    \"\"\"Compute metrics for evaluation\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):  # if the model also returns hidden_states or attentions\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(labels, predictions),\n",
    "        'Precision': precision_score(labels, predictions,average='binary'),\n",
    "        'Recall': recall_score(labels, predictions,average='binary'),\n",
    "        'F1 Score': f1_score(labels, predictions,average='binary'),\n",
    "        # 'Classification Report': classification_report(labels, predictions, output_dict=True)  # output_dict=True ensures a dict is returned\n",
    "    }\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def train() -> None:\n",
    "    \"\"\"\n",
    "    Train the model and save it to the Hugging Face Hub.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"AutoModelForSequenceClassification\")\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # TRAIN\n",
    "    trainer.train()\n",
    "\n",
    "    # SAVE AND EVALUATE\n",
    "    tokenizer.save_pretrained(REPOSITORY_ID)\n",
    "    trainer.create_model_card()\n",
    "    trainer.push_to_hub()\n",
    "    print(trainer.evaluate())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlanT5 task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "from huggingface_hub import HfFolder\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score, precision_score,recall_score,f1_score\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mnt/Data/rishav_2311mc12/anaconda3/envs/TextTime/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/mnt/Data/rishav_2311mc12/anaconda3/envs/TextTime/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022917fd562240959908da6095863d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5945 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd7e64d52224c6fbc58c584b9a1f74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /mnt/Data/rishav_2311mc12/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='128' max='29725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  128/29725 00:50 < 3:16:32, 2.51 it/s, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2id = {\"0\": 0, \"1\": 1}\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "\n",
    "def format_data_T2(row, flag=-1):\n",
    "    prompt = f\"Old sentence: {row['old_cleaned_content']}\\n[SEP]\\nNew sentence: {row['new_cleaned_content']}\\nAnswer:\"\n",
    "    completion = \"Yes\" if row['Ground-Truth'] == 1 else \"No\"\n",
    "\n",
    "    base_prompt = \"\"\"'Determine whether a text passage has been updated by identifying changes in date, numbers, scores, statuses, or other relevant information between two given sentences. Provide a binary answer (Yes/No) indicating if the new sentence represents an update to the old sentence.'\"\"\"\n",
    "\n",
    "    formatted_entry = {\"prompt\": base_prompt + prompt, \"completion\": completion} if flag == 1 else {\"prompt\": base_prompt + prompt, \"completion\": ''}\n",
    "    return json.dumps(formatted_entry)\n",
    "\n",
    "def load_dataset(model_type: str = \"\") -> Dataset:\n",
    "    if model_type == \"AutoModelForSequenceClassification\":\n",
    "        train_df = pd.read_csv(\"train.csv\", encoding='ISO-8859-1')\n",
    "        test_df = pd.read_csv(\"val.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "        train_df[\"text\"] = train_df.apply(lambda row: format_data_T2(row, flag=0), axis=1)\n",
    "        test_df[\"text\"] = test_df.apply(lambda row: format_data_T2(row, flag=0), axis=1)\n",
    "\n",
    "\n",
    "        # Apply the function to each row and store the result in a new column 'text'\n",
    "        train_df.drop(columns=['old_cleaned_content','new_cleaned_content'], inplace=True)\n",
    "        test_df.drop(columns=['old_cleaned_content','new_cleaned_content'], inplace=True)\n",
    "\n",
    "        train_df.rename(columns={'Ground-Truth': 'labels'}, inplace=True)\n",
    "        test_df.rename(columns={'Ground-Truth': 'labels'}, inplace=True) \n",
    "\n",
    "        dataset_train = Dataset.from_pandas(train_df)\n",
    "        dataset_test = Dataset.from_pandas(test_df)\n",
    "\n",
    "        dataset = DatasetDict({\n",
    "            'train': dataset_train,\n",
    "            'test': dataset_test\n",
    "        })  \n",
    "\n",
    "    return dataset\n",
    "\n",
    "MODEL_ID = \"google/flan-t5-large\"\n",
    "REPOSITORY_ID = \"rishavranaut/flanT5_Task1\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    MODEL_ID, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model.to(\"cuda\") if torch.cuda.is_available() else model.to(\"cpu\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=5,\n",
    "    output_dir = REPOSITORY_ID,\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    weight_decay = 0.01,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=2500,\n",
    "    report_to=\"tensorboard\",\n",
    "    evaluation_strategy = 'steps',\n",
    "    save_strategy='steps',\n",
    "    save_steps=2500, \n",
    "    load_best_model_at_end = False,\n",
    "    save_total_limit=2,\n",
    "    push_to_hub=True,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id= REPOSITORY_ID,\n",
    "    hub_token='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',\n",
    "    resume_from_checkpoint=True\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize_function(examples) -> dict:\n",
    "    \"\"\"Tokenize the text column in the dataset\"\"\"\n",
    "    sentences = [\n",
    "        text for text in examples['text']\n",
    "    ]\n",
    "    return tokenizer(sentences, truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "def compute_metrics(eval_pred) -> dict:\n",
    "    \"\"\"Compute metrics for evaluation\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):  # if the model also returns hidden_states or attentions\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(labels, predictions),\n",
    "        'Precision': precision_score(labels, predictions,average='binary'),\n",
    "        'Recall': recall_score(labels, predictions,average='binary'),\n",
    "        'F1 Score': f1_score(labels, predictions,average='binary'),\n",
    "        # 'Classification Report': classification_report(labels, predictions, output_dict=True)  # output_dict=True ensures a dict is returned\n",
    "    }\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def train() -> None:\n",
    "    \"\"\"\n",
    "    Train the model and save it to the Hugging Face Hub.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"AutoModelForSequenceClassification\")\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # TRAIN\n",
    "    trainer.train()\n",
    "\n",
    "    # SAVE AND EVALUATE\n",
    "    tokenizer.save_pretrained(REPOSITORY_ID)\n",
    "    trainer.create_model_card()\n",
    "    trainer.push_to_hub()\n",
    "    print(trainer.evaluate())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextTime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
